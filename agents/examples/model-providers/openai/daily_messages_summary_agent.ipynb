{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from xpander_sdk import XpanderClient, LLMProvider, OpenAISupportedModels\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict, Any\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "# Setup Logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "OpenAPIKey = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "xpanderAPIKey = os.environ.get(\"XPANDER_API_KEY\", \"\")\n",
    "xpanderAgentID = os.environ.get(\"XPANDER_AGENT_ID\", \"\")\n",
    "\n",
    "openai_client = OpenAI(api_key=OpenAPIKey)\n",
    "xpander_client = XpanderClient(api_key=xpanderAPIKey, base_url=\"https://inbound.stg.xpander.ai\")\n",
    "xpander_agent = xpander_client.agents.get(agent_id=xpanderAgentID)\n",
    "\n",
    "class SharedMemory:\n",
    "    def __init__(self):\n",
    "        self.memory = []\n",
    "\n",
    "    def add_message(self, content: str, role: str = \"assistant\", agent_name: str = None):\n",
    "        self.memory.append({\"role\": role, \"content\": content, \"agent_name\": agent_name})\n",
    "\n",
    "    def get_memory(self) -> list:\n",
    "        return self.memory\n",
    "\n",
    "\n",
    "class PlannerAgent:\n",
    "    def __init__(self, handler, tools: list, task_message: str, system_message: str, shared_memory: SharedMemory,\n",
    "                 finish_message: str = \"Final Answer\"):\n",
    "        self.handler = handler\n",
    "        self.tools = tools\n",
    "        self.task_message = task_message\n",
    "        self.system_message = system_message\n",
    "        self.shared_memory = shared_memory\n",
    "        self.local_memory = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": task_message},\n",
    "        ]\n",
    "        self.finish_message = finish_message\n",
    "        self.is_finished = False\n",
    "        self.step_number = 1\n",
    "    def invoke_llm(self, memory, tools=None, model=OpenAISupportedModels.GPT_4_O, max_tokens=16384):\n",
    "        try:\n",
    "            response = self.handler.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=memory,\n",
    "                tools=tools,\n",
    "                tool_choice=\"none\",\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=0.0, \n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error invoking LLM: {e}\")\n",
    "        \n",
    "    def run_post_processing(self, response: str) -> str:\n",
    "        \"\"\"\n",
    "        Post-process the LLM response to check for completion.\n",
    "        \"\"\"\n",
    "        if re.search(self.finish_message, response):\n",
    "            self.is_finished = True \n",
    "        return response\n",
    "\n",
    "    def finished(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the agent has completed its task.\n",
    "        \"\"\"\n",
    "        return self.is_finished\n",
    "\n",
    "\n",
    "\n",
    "class ToolSelectorAgent:\n",
    "    def __init__(self, handler, tools: list, task_message: str, system_message: str, shared_memory: SharedMemory):\n",
    "        self.handler = handler\n",
    "        self.tools = tools\n",
    "        self.task_message = task_message\n",
    "        self.system_message = system_message\n",
    "        self.shared_memory = shared_memory\n",
    "        self.local_memory = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": task_message},\n",
    "        ]\n",
    "        self.selected_tools = []\n",
    "\n",
    "    def invoke_llm(self, memory, tools=None, model=OpenAISupportedModels.GPT_4_O, max_tokens=16384):\n",
    "        try:                                \n",
    "            response=self.handler.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=memory,\n",
    "                tools=tools,\n",
    "                parallel_tool_calls=False,\n",
    "                tool_choice=\"required\",\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=0.0,\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error invoking LLM: {e}\")\n",
    "\n",
    "class ParserAgent:\n",
    "    def __init__(self, handler, tools: list, task_message: str, system_message: str, shared_memory: SharedMemory):\n",
    "        self.handler = handler\n",
    "        self.task_message = task_message\n",
    "        self.system_message = system_message\n",
    "        self.tools = tools\n",
    "        self.shared_memory = shared_memory\n",
    "        self.local_memory = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": task_message},\n",
    "        ]\n",
    "    def invoke_llm(self, memory, tools=None, model=OpenAISupportedModels.GPT_4_O, max_tokens=16384):\n",
    "        try:\n",
    "            response=self.handler.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=memory,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=0.0,\n",
    "                tools=tools,\n",
    "                tool_choice=\"none\"\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error invoking LLM ParserAgent: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_planner = '''As a planner agent your task is to breakdown the main task into sub tasks that fulfill the main task. \n",
    "your main task is to retrieve only unread messages from Slack and from Gmail from the last 24 hours (today is {current_date}) and create a report in Notion.\n",
    "'''\n",
    "tool_selector_system_prompt = '''You are an tool selector agent responsible for selecting the correct tool with the most relevant parameters that will fullfil the task your will received from the planner agent to execute the plan.\n",
    "'''\n",
    "parser_system_prompt = '''You are a parser agent. Your job is to process raw outputs from tool calls and extract actionable information that can help fulfill the user request. You must ensure the extracted data is relevant, accurate, and formatted for easy use by the Planner Agent.\n",
    "'''\n",
    "planner_task_prompt = '''\n",
    "As a planner research agent your task is to plan the the full workflow for the tool execution agent and the parser agent for fetching unread messages from Slack (only direct messages) and unread mails from Gmail from the last 24 hours,\n",
    "and create a new page inside the 'daily reports' in Notion titled 'Daily Messages Summary - {current_date}' and populate it with the messages data.\n",
    "you need to explain each step in the workflow, what is the current required data and what are the expected results.\n",
    "\n",
    "what expected from you:\n",
    "Retreive all the unread messeges from Slack - Only direct messages (DMs) from the last 24 hours, retrieve all unread mails from Gmail from the last 24 hours. \n",
    "after you finish to retrieve all the messages data from Slack and Gmail you need to create a new page inside the 'daily reports' database title as 'Daily Messages Summary - {current_date}' in Notion that contains all of messages data report.\n",
    "\n",
    "rules:\n",
    "1. you MUST said what is the current date in the response - today is {current_date}. it is very important for retreiving the correct messages from Gmail and Slack!!\n",
    "2. You must retreive all the unread messages data from Slack (only direct messages) and Gmail when creating the final page!\n",
    "3. on Slack You must go over each message in List User's Conversations and extract all the Unread direct messages data -  you MUST return the people names NOT ID.\n",
    "4. The final answer must include a link to the new Notion page. \n",
    "5. after you finished to retrieve all the messages data from Slack and Gmail you must create the final page in Notion.\n",
    "6. the new page in Notion must be inside the 'daily reports' page and titled \"Daily Messages Summary - {current_date}\" \n",
    "7. you must Populate the new page with \"Daily Messages Summary - {current_date}\" a table containing the following columns:\n",
    "  - **Application**: The application that the message is from Gmail or Slack.\n",
    "  - **Tag**: The message topic or category.\n",
    "  - **Participants**: all the people included in each message.\n",
    "  - **Response Needed**: Whether a response is expected.\n",
    "  - **Urgency**: Highlights if the message is urgent (high, medium, low).\n",
    "  - **Summary**: A brief overview of the message content.\n",
    "\n",
    "\n",
    "this is the expected output template:\n",
    "if the query has not been fulfilled:\n",
    "Plan step (i+1): [the next step of your plan for how to solve the query].\n",
    "\n",
    "if all the messages fetching from Slack and Gmail is finished and the page is created in Notion you'll return the final answer only block child has been appended at least 1 time in Notion.\n",
    "you'll return a link to the page you need to return by the following template:\n",
    "Final Answer: [link to the new page that created for Daily Messages Summary - {current_date}].\n",
    "\n",
    "These are the strict rules:\n",
    "1. Always provide your plan in natural language, ensuring it is closely related to the input tools, you must related to the available tools you got.\n",
    "2. Be specific in the plan and explain what should be the results of this step after parsing the API response. \n",
    "3. Only if all unread messages data retreived from Slack and Gmail from the last 24 houres and the Notion page created with all information is ready and you got the link to this new page the user's query has been fulfilled and you need to return the output the answer immediately with the prefix: Final Answer: [link to the new page that created for the daily messages summary - {current_date}].\n",
    "4. User's query can't be fulfilled without at least one 'Parser Response'. You can't fulfill task without at least one API calling and response.\n",
    "5. If the query has not been fulfilled, explain how to fix the last step and continue to output your plan.\n",
    "6. Return only the next Plan step (i+1) you generated and do not mention all the steps list until now. you'll get the conversation history Plan steps [1,...,i-1] and API responses after parsing, you will use it to generate the next step.\n",
    "7. If the the API request failed, return how you recommend to handle this error in the next retry of the tool calling.\n",
    "8. you must return only one step in each call! never return the full step pipeline in one iteration.\n",
    "9. never create the final page before you featch all the messages data from Slack and Gmail if exist!\n",
    "10. if there is no messages data from Slack or from Gmail you must return that you not found any messages and you are moving to the next step. also you must mention it in the final report in Notion.\n",
    "11. all the retreived messages data can be founded in the previous steps after each prefix phrase: \n",
    "'here is the messages data that you retreive:'\n",
    "[the resource tool Slack or Gmail response].\n",
    "12. You will return the Final Answer only after fetchin all the messages data from Slack and Gmail and creating the final page in Notion. you can't return the final answer without using all tools and creating new blocks inside the page!\n",
    "13. validate that you return all the people names or channel names NOT ID in the final report in Notion.\n",
    "\n",
    "please start with the first step and return only one step in each call!\n",
    "your daily messages summary report for {current_date} begin now...\n",
    "'''\n",
    "tool_selector_task_prompt = '''\n",
    "as part of the multi agent pipeline you are the tool selector agent that will select the most accurate tool to fulfill the current task provided by the planner agent.\n",
    "Your tasks:\n",
    "1. Select the most accurate tool to fulfill the current task provided by the planner agent. \n",
    "2. Generate all required parameters by the schema you got that will fulfill the task.\n",
    "3. You must return your answer as a tool_call with the function name and relevant arguments.\n",
    "4. If the planer explain about the error and how to fix it, you should fix the last tool call parameters and return the new tool call.\n",
    "5. when you creating the final Notion page you must used all the previews messages that collected in the parserAgent response steps.\n",
    "6. you must fill all 'Daily Messages Summary - {current_date}' database table columns (properties) inside 'daily reports' by using the correct typing.\n",
    "7. the new page blocks will includes the a table with the following columns: Application, Tag, Participants, Response Needed, Urgency, Summary.\n",
    "8. you must use all the previews Parser Agent messages that include slack and gmail messages data.\n",
    "'''\n",
    "\n",
    "parser_task_prompt = '''\n",
    "as part of the multi agent pipeline you are the parser agent and your task is to get the current step plan and the response from the tool that executed for this plan and parse this response to fulfill the plan.\n",
    "your response should contains all the relevent details for the report without missing information.\n",
    "\n",
    "These are the strict rules:\n",
    "1. validate that you finished to extract all the unread direct messages (DMs) from Slack. you MUST go over each direct message in 'List User's Conversations' and extract all the Unread direct messages data. if you can't read a message continue to the next message in the list. you must ran over all the messages in the list.only when you finish to extract all the messages data you can tell the planner agent that you finished this step and all the messages data is ready.\n",
    "2. you must validate that all the unread messages from Gmail retrieved successfully.count how many messages you get in List Messages, and than pay attention to extract all the messages data in the list. only when you finish to extract all the messages data you can tell the planner agent that you finished this step and all the messages data is ready.\n",
    "3. after you finished to extract all the unread messages relevant data from Gmail you must Implement clustering logic to organize messages by related topics for easy viewing.\n",
    "4. if there is no messages data from Slack or from Gmail you must return that you not found any messages and you can be moving to the next step.\n",
    "5. you must fill all 'Daily Messages Summary - {current_date}' database table columns (properties) by using the correct typing.\n",
    "6. only when 'The selected Tool:' is Notion create page it means that created a new page and you must return:\n",
    " page link: [link to this page]\n",
    " page id: [the new final page id]\n",
    " text: 'blocks not created yet, now need to add the information inside the blocks page.'\n",
    "7. the new page blocks will MUST includes the a table with the following columns: \n",
    "  - **Application**: The application that the message is from Gmail or Slack.\n",
    "  - **Tag**: The message topic or label (e.g: 'Meeting', 'Task', 'Event', 'Reminder', 'Notification', 'Alert', 'Transaction'...).\n",
    "  - **Participants**: All the People included in each message. people names NOT ID separated by commas.\n",
    "  - **Response Needed**: Whether a response is expected.\n",
    "  - **Urgency**: Highlights if the message is urgent (high, medium, low).\n",
    "  - **Summary**: A brief overview of the message content.\n",
    "8. only when 'The selected Tool:' is 'append new block children' it means that blocks are created. you should return the page link with the message: 'block child has been appended in the [iter number (how many times the blocks created successfully)] time'.\n",
    "9. you must return the report as human readable text that include all the information.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tools = xpander_agent.get_tools()\n",
    "current_date = datetime.now().date()\n",
    "shared_memory = SharedMemory()\n",
    "\n",
    "# Initialize Agents\n",
    "planner_agent = PlannerAgent(handler=openai_client,tools=tools, task_message=planner_task_prompt.format(current_date=current_date), system_message=system_prompt_planner.format(current_date=current_date),shared_memory=shared_memory)\n",
    "tool_selector_agent = ToolSelectorAgent(handler=openai_client,tools=tools,task_message=tool_selector_task_prompt.format(current_date=current_date),system_message=tool_selector_system_prompt , shared_memory=shared_memory)\n",
    "parser_agent = ParserAgent(handler=openai_client, tools=tools, task_message=parser_task_prompt.format(current_date=current_date) ,system_message=parser_system_prompt, shared_memory=shared_memory)\n",
    "\n",
    "\n",
    "planner_response = planner_agent.invoke_llm(memory=planner_agent.local_memory,tools=planner_agent.tools)\n",
    "shared_memory.add_message(planner_response.choices[0].message.content,role=\"assistant\",agent_name=\"PlannerAgent\")\n",
    "logger.info(\"Planner Response: %s\", planner_response.choices[0].message.content)\n",
    "\n",
    "tool_selector_response = tool_selector_agent.invoke_llm(memory=tool_selector_agent.local_memory+shared_memory.get_memory(),tools=tools)\n",
    "tool_calls = xpander_client.extract_tool_calls(llm_response=tool_selector_response.model_dump(), llm_provider=LLMProvider.OPEN_AI)\n",
    "_ = xpander_agent.run_tools(tool_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_memory = SharedMemory()\n",
    "tools = xpander_agent.get_tools()\n",
    "\n",
    "planner_response = planner_agent.invoke_llm(memory=planner_agent.local_memory,tools=tools)\n",
    "shared_memory.add_message(planner_response.choices[0].message.content,role=\"assistant\",agent_name=\"PlannerAgent\")\n",
    "logger.info(\"Planner Response: %s\", planner_response.choices[0].message.content)\n",
    "\n",
    "while not planner_agent.finished():\n",
    "    try:\n",
    "\n",
    "        # Step 2: Tool Selector Agent\n",
    "        tool_selector_response = tool_selector_agent.invoke_llm(memory=tool_selector_agent.local_memory+shared_memory.get_memory(),tools=tools)\n",
    "        tool_calls = xpander_client.extract_tool_calls(llm_response=tool_selector_response.model_dump(), llm_provider=LLMProvider.OPEN_AI)\n",
    "        logger.info(\"Tool calls: %s\", tool_calls)\n",
    "        if tool_calls:\n",
    "            for tool_call in tool_calls:\n",
    "                tool_response = xpander_agent.run_tool(tool_call)\n",
    "                logger.info(\"Tool response: %s\", tool_response.result)\n",
    "                \n",
    "                selected_tool_params = json.dumps(tool_selector_response.model_dump()['choices'][0]['message']['tool_calls'])\n",
    "                selected_tool_data = {\n",
    "                    \"selected_tool\": tool_call.name,\n",
    "                    \"tool_call_id\": tool_call.tool_call_id,\n",
    "                    \"params\": selected_tool_params,\n",
    "                    \"response\": tool_response.result\n",
    "                }\n",
    "                logger.info(\"Tool selector response: %s\", json.dumps(selected_tool_data))\n",
    "                \n",
    "                parser_message = (\n",
    "                    f\"Current Task: {planner_response.choices[0].message.content}\\n\"\n",
    "                    f\"The selected Tool: {tool_call.name}\\n\"\n",
    "                    f\"The params Tool: {json.dumps(selected_tool_data)}\\n\"\n",
    "                )\n",
    "\n",
    "                parser_response = parser_agent.invoke_llm(memory=parser_agent.local_memory+shared_memory.get_memory()+[{\"role\": \"user\", \"content\": parser_message}],tools=tools)\n",
    "                shared_memory.add_message(parser_response.choices[0].message.content,role=\"assistant\",agent_name=\"ParserAgent\")\n",
    "                logger.info(\"Parser response: %s\", parser_response.choices[0].message.content)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline error: {e}\")\n",
    "        break\n",
    "    \n",
    "    tools = xpander_agent.get_tools()\n",
    "    planner_response = planner_agent.invoke_llm(memory=planner_agent.local_memory+shared_memory.get_memory(),tools=tools)\n",
    "    shared_memory.add_message(planner_response.choices[0].message.content,role=\"assistant\",agent_name=\"PlannerAgent\")\n",
    "    logger.info(\"Planner response: %s\", planner_response.choices[0].message.content)\n",
    "    \n",
    "    planner_agent.run_post_processing(planner_response.choices[0].message.content)\n",
    "\n",
    "logger.info(\"Pipeline execution complete!\")\n",
    "logger.info(\"Shared Memory:\")\n",
    "logger.info(shared_memory.get_memory())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
